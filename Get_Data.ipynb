{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Data.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxMera/Deep-Learning---denoising-rs-fMRI/blob/master/Get_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBgg-3c7Hihb",
        "colab_type": "text"
      },
      "source": [
        "### Hand-Training Datasets\n",
        "Here are data sets of the human connectome project manually classified for FIX.\n",
        "\n",
        "https://www.fmrib.ox.ac.uk/datasets/FIX-training/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2D_WxQgFRTE",
        "colab_type": "text"
      },
      "source": [
        "### Connected to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gyItqjtFLBa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6e2eefa2-eead-4c9e-8326-916c85cdddf8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNmADu6MFmkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "1b76d98f-331e-4f30-8ecb-ad8a55f07b4d"
      },
      "source": [
        "!pip install tqdm\n",
        "!pip install nilearn\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "import scipy.io as sio\n",
        "from nilearn import image\n",
        "from nilearn import plotting\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, Lambda\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "print (tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Collecting nilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/65/ba76e7cd544dafc28960e60b099d6f906a2096034c560158beaf2ff299bc/nilearn-0.5.2-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from nilearn) (2.3.3)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (0.98)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from nibabel>=2.0.2->nilearn) (1.17.4)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kpaHBtMHKPa",
        "colab_type": "text"
      },
      "source": [
        "### Download data\n",
        "HCP_hp2000       TR=0.7\n",
        "\n",
        "Hand_clasifi*        TR=2.0\n",
        "\n",
        "Standard        TR=3.0\n",
        "\n",
        "WhII_MB6       TR=1.3\n",
        "\n",
        "WhII Standard     TR=3.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEGx4HJZHIs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gz=glob.glob('*.tar.gz')\n",
        "files=np.shape(gz)[0]\n",
        "\n",
        "if files==0:\n",
        "  #Download\n",
        "  os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_runs1-20.tar.gz')\n",
        "  os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_runs21-40.tar.gz')\n",
        "  os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_runs41-60.tar.gz')\n",
        "  os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_runs61-80.tar.gz')\n",
        "  os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_runs81-100.tar.gz')  \n",
        "  #os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/HCP_hp2000_run1.tar.gz')\n",
        "  #os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/WhII_MB6.tar.gz')\n",
        "  #os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/WhII_Standard.tar.gz')\n",
        "  #os.system('wget https://www.fmrib.ox.ac.uk/datasets/FIX-training/Standard.tar.gz')\n",
        "else:\n",
        "  print('The files already exist')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NXd00MI26V",
        "colab_type": "text"
      },
      "source": [
        "### Find .tar files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM9hhRc0IxPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98f95bac-0dfa-4d25-d050-37afab98a29d"
      },
      "source": [
        "compri=glob.glob('*.tar.gz')\n",
        "print('tar.gz files ', np.shape(compri)[0])\n",
        "\n",
        "if os.path.exists('AllData'):\n",
        "  print('The folder already exist')\n",
        "else:\n",
        "  print('creating folder...')\n",
        "  os.system('mkdir AllData')\n",
        "  print('...folder AllData created.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar.gz files  5\n",
            "creating folder...\n",
            "...folder AllData created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQSGI1Q5J0bw",
        "colab_type": "text"
      },
      "source": [
        "### Unzip Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnkvoQG7I_Yh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2cf36970-7a3d-4738-9eac-850ce4d2c8f5"
      },
      "source": [
        "files=glob.glob('AllData/*')\n",
        "folde=np.shape(files)[0]\n",
        "\n",
        "if folde==0:\n",
        "  for i in compri:\n",
        "    print('unziping '+i+' in AllData')\n",
        "    os.system('tar -xzvf '+i+' -C AllData')\n",
        "else: \n",
        "  print('folders already unzipped')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unziping HCP_hp2000_runs21-40.tar.gz in AllData\n",
            "unziping HCP_hp2000_runs41-60.tar.gz in AllData\n",
            "unziping HCP_hp2000_runs81-100.tar.gz in AllData\n",
            "unziping HCP_hp2000_runs61-80.tar.gz in AllData\n",
            "unziping HCP_hp2000_runs1-20.tar.gz in AllData\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkGbl658J6k9",
        "colab_type": "text"
      },
      "source": [
        "### Groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqCKsCHCJqzV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee0c049d-e7b4-4657-c627-f4486f5b4587"
      },
      "source": [
        "Carpetas=np.sort(glob.glob('AllData/HCP*'))\n",
        "print(Carpetas)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AllData/HCP_hp2000']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enUnAr0PKBiW",
        "colab_type": "text"
      },
      "source": [
        "### Subjects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSyipebMJstE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbe12fa1-5c4b-42dd-e85c-6dd75facc359"
      },
      "source": [
        "for car in Carpetas:\n",
        "  sujetos=glob.glob(car+'/*')\n",
        "  print(np.shape(sujetos)[0],'Sujects on ', car)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 Sujects on  AllData/HCP_hp2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFWf8_X5KZOc",
        "colab_type": "text"
      },
      "source": [
        "# Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lqKbuzKyxi",
        "colab_type": "text"
      },
      "source": [
        "### Images with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0F05myULXq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "brain_pca = PCA(n_components=3)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "def PCA_Images(imasx,k):\n",
        "  sag, cr, ax, cp=np.shape(imasx)\n",
        "  if k>cp or k<0:\n",
        "    print('The component number',str(k),' doesnt exist')\n",
        "  #Axial\n",
        "  brainF = np.zeros((1, sag*cr))\n",
        "  ima3D=np.zeros((sag,cr,3))  \n",
        "  for sl in range(ax):    \n",
        "    slic=np.transpose(imasx[:,:,sl,k].flatten())\n",
        "    brainF = np.concatenate((brainF,[slic]), axis=0)\n",
        "  brainF=brainF[1:,:]  \n",
        "  brain_pca.fit(brainF) \n",
        "\n",
        "  ima = np.transpose(brain_pca.components_)\n",
        "  ima = np.transpose(scaler.fit_transform(ima))\n",
        "  ima=(ima+1)*255/2\n",
        "  ima[ima<0]=0\n",
        "  ima[ima>255]=255 \n",
        "  for chanel in range(3):\n",
        "    ima3D[:,:,chanel]=ima[chanel].reshape(sag,cr)\n",
        "  ima3D=np.array(ima3D, np.dtype('uint8'))\n",
        "\n",
        "  #Coronal\n",
        "  brainC = np.zeros((1, sag*ax))\n",
        "  ima3C=np.zeros((sag,ax,3))  \n",
        "  for sl in range(cr):    \n",
        "    slic=np.transpose(imasx[:,sl,:,k].flatten())\n",
        "    brainC = np.concatenate((brainC,[slic]), axis=0)\n",
        "  brainC=brainC[1:,:]  \n",
        "  brain_pca.fit(brainC) \n",
        "\n",
        "  imaC = np.transpose(brain_pca.components_)\n",
        "  imaC = np.transpose(scaler.fit_transform(imaC))\n",
        "  imaC=(imaC+1)*255/2\n",
        "  imaC[imaC<0]=0\n",
        "  imaC[imaC>255]=255 \n",
        "  for chanel in range(3):\n",
        "    ima3C[:,:,chanel]=imaC[chanel].reshape(sag,ax)\n",
        "  ima3C=np.array(ima3C, np.dtype('uint8'))\n",
        "\n",
        "  #Sagital\n",
        "  brainS = np.zeros((1, cr*ax))\n",
        "  ima3S=np.zeros((ax,cr,3))  \n",
        "  for sl in range(sag):    \n",
        "    slic=np.transpose(imasx[sl,:,:,k].flatten())\n",
        "    brainS = np.concatenate((brainS,[slic]), axis=0)\n",
        "  brainS=brainS[1:,:]  \n",
        "  brain_pca.fit(brainS) \n",
        "\n",
        "  imaS = np.transpose(brain_pca.components_)\n",
        "  imaS = np.transpose(scaler.fit_transform(imaS))\n",
        "  imaS=(imaS+1)*255/2\n",
        "  imaS[imaS<0]=0\n",
        "  imaS[imaS>255]=255 \n",
        "  for chanel in range(3):\n",
        "    ima3S[:,:,chanel]=np.flip(np.transpose(imaS[chanel].reshape(cr,ax)))\n",
        "  ima3S=np.array(ima3S, np.dtype('uint8'))\n",
        "  imgn=cv2.hconcat([ima3D, ima3C, ima3S])\n",
        "  return imgn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9_m2Q4wKu6N",
        "colab_type": "text"
      },
      "source": [
        "### Images with 3D threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDdmUN-2M-ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel=np.ones((4,4))\n",
        "umb=2\n",
        "def threshold_3D(masx, umb, k):\n",
        "  sag, cr, ax, cp=np.shape(masx)\n",
        "\n",
        "  #Axial\n",
        "  ima3D=np.zeros((sag,cr,3))\n",
        "  for z in range(8):\n",
        "    val=2**z\n",
        "    bina0=np.array((masx[:,:,int(11+z*3),k]>umb)*val, np.dtype('uint8'))\n",
        "    bina0 = cv2.morphologyEx(bina0, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3D[:,:,0]=ima3D[:,:,0]+bina0\n",
        "\n",
        "    bina1=np.array((masx[:,:,int(35+z*3),k]>umb)*val, np.dtype('uint8'))\n",
        "    bina1 = cv2.morphologyEx(bina1, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3D[:,:,1]=ima3D[:,:,1]+bina1\n",
        "\n",
        "    bina2=np.array((masx[:,:,int(59+z*3),k]>umb)*val, np.dtype('uint8'))\n",
        "    bina2 = cv2.morphologyEx(bina2, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3D[:,:,2]=ima3D[:,:,2]+bina2\n",
        "\n",
        "  #Coronal\n",
        "  ima3C=np.zeros((sag,ax,3))\n",
        "  for z in range(8):\n",
        "    val=2**z\n",
        "    bina0=np.array((masx[:,int(20+z*3),:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina0 = cv2.morphologyEx(bina0, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3C[:,:,0]=ima3C[:,:,0]+bina0\n",
        "\n",
        "    bina1=np.array((masx[:,int(44+z*3),:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina1 = cv2.morphologyEx(bina1, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3C[:,:,1]=ima3C[:,:,1]+bina1\n",
        "\n",
        "    bina2=np.array((masx[:,int(68+z*3),:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina2 = cv2.morphologyEx(bina2, cv2.MORPH_CLOSE, kernel)\n",
        "    ima3C[:,:,2]=ima3C[:,:,2]+bina2\n",
        "  \n",
        "  #sagittal\n",
        "  ima3S=np.zeros((ax,cr,3))\n",
        "  for z in range(8):\n",
        "    val=2**z\n",
        "    bina0=np.array((masx[int(11+z*3),:,:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina0 = np.transpose(cv2.morphologyEx(bina0, cv2.MORPH_CLOSE, kernel))\n",
        "    ima3S[:,:,0]=ima3S[:,:,0]+bina0\n",
        "\n",
        "    bina1=np.array((masx[int(35+z*3),:,:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina1 = np.transpose(cv2.morphologyEx(bina1, cv2.MORPH_CLOSE, kernel))\n",
        "    ima3S[:,:,1]=ima3S[:,:,1]+bina1\n",
        "\n",
        "    bina2=np.array((masx[int(59+z*3),:,:,k]>umb)*val, np.dtype('uint8'))\n",
        "    bina2 = np.transpose(cv2.morphologyEx(bina2, cv2.MORPH_CLOSE, kernel))\n",
        "    ima3S[:,:,2]=ima3S[:,:,2]+bina2\n",
        "  imgn=cv2.hconcat([ima3D, ima3C, np.flip(ima3S)])\n",
        "  imx=np.array(imgn, np.dtype('uint8'))  \n",
        "  return imx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRuW48gDMtlV",
        "colab_type": "text"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rimMTks5M4a8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb918747-464a-4e1a-aa04-ace97a75b1b8"
      },
      "source": [
        "test='AllData/HCP_hp2000/1.ica'\n",
        "img=image.image.load_img(test+'/filtered_func_data.ica/melodic_IC.nii.gz')\n",
        "series=np.loadtxt(test+\"/filtered_func_data.ica/melodic_mix\")\n",
        "imasx=img.get_data()\n",
        "print('sagital, coronal, axial and components', np.shape(imasx))\n",
        "print('Time points ', np.shape(series)[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sagital, coronal, axial and components (91, 109, 91, 250)\n",
            "Time points  1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZIMqvQoMS6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aff80d6-554e-4680-d0af-79178545c7b8"
      },
      "source": [
        "kx=34 #Component\n",
        "imx=PCA_Images(imasx,kx)\n",
        "#imx=cv2.medianBlur(imx,3)\n",
        "im2=threshold_3D(imasx, 2, kx)\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.plot(series[:,kx])\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.imshow(imx)\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.imshow(im2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbf134056d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHo34f-8KHXh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28a48f7f-7e5f-4727-e9b1-b3672c314827"
      },
      "source": [
        "umb=2\n",
        "compSub=[]\n",
        "conver=np.vectorize(int)\n",
        "AllData=np.zeros((1200,1))\n",
        "AllLabels=[]\n",
        "orden=[]\n",
        "\n",
        "for fx in Carpetas:\n",
        "  subjects=glob.glob(fx+'/*')\n",
        "  subjects=np.sort(subjects)\n",
        "  os.system('mkdir '+fx[8:])\n",
        "  \n",
        "  for sub in subjects:\n",
        "    #Leer serie de tiempo\n",
        "    print(sub)\n",
        "    series=np.loadtxt(sub+\"/filtered_func_data.ica/melodic_mix\")\n",
        "    comp=np.shape(series)[1]\n",
        "\n",
        "    #get maps\n",
        "    img=image.image.load_img(sub+\"/filtered_func_data.ica/melodic_IC.nii.gz\")    \n",
        "    masx=img.get_data()\n",
        "\n",
        "    for k in range(comp):\n",
        "      #imx=PCA_Images(imasx,k)\n",
        "      imx=threshold_3D(imasx, 2, k)\n",
        "\n",
        "      name=fx[8:]+'/sub-'+sub[len(fx)+1:-4]+'-comp-'+str(k)+'.png'\n",
        "      cv2.imwrite(name, imx)\n",
        "      orden.append(name)\n",
        "\n",
        "    #print('Time and Components per subject ', np.shape(series))\n",
        "    if np.shape(series)[0]==1200:\n",
        "      compSub.append(comp)\n",
        "      #print('Time and Components per subject ', np.shape(series))\n",
        "      label1=np.ones(comp)    \n",
        "      AllData=np.concatenate((AllData,series), axis=1)\n",
        "      \n",
        "      #Leer etiquetas manuales\n",
        "      f = open(sub+\"/hand_labels_noise.txt\") \n",
        "      while True:\n",
        "        line = f.readline()\n",
        "        if line=='':\n",
        "          break\n",
        "        handClas=line[1:-2]\n",
        "      handClas= handClas.split(\", \")\n",
        "      handClas=conver(handClas)-1\n",
        "      label1[handClas]=0\n",
        "      AllLabels=np.concatenate((AllLabels, label1))\n",
        "      #print('Noise per subject ', np.shape(handClas))\n",
        "      f.close()\n",
        "    \n",
        "AllData=AllData[:,1:]\n",
        "sio.savemat(fx[8:]+'/Data.mat', {'series': AllData})\n",
        "sio.savemat(fx[8:]+'/Labels.mat', {'labels': AllLabels})\n",
        "sio.savemat(fx[8:]+'/Order.mat', {'order': orden})\n",
        "\n",
        "os.system('zip -r '+fx[8:]+'.zip '+fx[8:])\n",
        "os.system('mv '+fx[8:]+'.zip '+'drive/My\\ Drive/DatosDeepLearning/COLOR-'+fx[8:]+'.zip')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AllData/HCP_hp2000/1.ica\n",
            "AllData/HCP_hp2000/10.ica\n",
            "AllData/HCP_hp2000/100.ica\n",
            "AllData/HCP_hp2000/11.ica\n",
            "AllData/HCP_hp2000/12.ica\n",
            "AllData/HCP_hp2000/13.ica\n",
            "AllData/HCP_hp2000/14.ica\n",
            "AllData/HCP_hp2000/15.ica\n",
            "AllData/HCP_hp2000/16.ica\n",
            "AllData/HCP_hp2000/17.ica\n",
            "AllData/HCP_hp2000/18.ica\n",
            "AllData/HCP_hp2000/19.ica\n",
            "AllData/HCP_hp2000/2.ica\n",
            "AllData/HCP_hp2000/20.ica\n",
            "AllData/HCP_hp2000/21.ica\n",
            "AllData/HCP_hp2000/22.ica\n",
            "AllData/HCP_hp2000/23.ica\n",
            "AllData/HCP_hp2000/24.ica\n",
            "AllData/HCP_hp2000/25.ica\n",
            "AllData/HCP_hp2000/26.ica\n",
            "AllData/HCP_hp2000/27.ica\n",
            "AllData/HCP_hp2000/28.ica\n",
            "AllData/HCP_hp2000/29.ica\n",
            "AllData/HCP_hp2000/3.ica\n",
            "AllData/HCP_hp2000/30.ica\n",
            "AllData/HCP_hp2000/31.ica\n",
            "AllData/HCP_hp2000/32.ica\n",
            "AllData/HCP_hp2000/33.ica\n",
            "AllData/HCP_hp2000/34.ica\n",
            "AllData/HCP_hp2000/35.ica\n",
            "AllData/HCP_hp2000/36.ica\n",
            "AllData/HCP_hp2000/37.ica\n",
            "AllData/HCP_hp2000/38.ica\n",
            "AllData/HCP_hp2000/39.ica\n",
            "AllData/HCP_hp2000/4.ica\n",
            "AllData/HCP_hp2000/40.ica\n",
            "AllData/HCP_hp2000/41.ica\n",
            "AllData/HCP_hp2000/42.ica\n",
            "AllData/HCP_hp2000/43.ica\n",
            "AllData/HCP_hp2000/44.ica\n",
            "AllData/HCP_hp2000/45.ica\n",
            "AllData/HCP_hp2000/46.ica\n",
            "AllData/HCP_hp2000/47.ica\n",
            "AllData/HCP_hp2000/48.ica\n",
            "AllData/HCP_hp2000/49.ica\n",
            "AllData/HCP_hp2000/5.ica\n",
            "AllData/HCP_hp2000/50.ica\n",
            "AllData/HCP_hp2000/51.ica\n",
            "AllData/HCP_hp2000/52.ica\n",
            "AllData/HCP_hp2000/53.ica\n",
            "AllData/HCP_hp2000/54.ica\n",
            "AllData/HCP_hp2000/55.ica\n",
            "AllData/HCP_hp2000/56.ica\n",
            "AllData/HCP_hp2000/57.ica\n",
            "AllData/HCP_hp2000/58.ica\n",
            "AllData/HCP_hp2000/59.ica\n",
            "AllData/HCP_hp2000/6.ica\n",
            "AllData/HCP_hp2000/60.ica\n",
            "AllData/HCP_hp2000/61.ica\n",
            "AllData/HCP_hp2000/62.ica\n",
            "AllData/HCP_hp2000/63.ica\n",
            "AllData/HCP_hp2000/64.ica\n",
            "AllData/HCP_hp2000/65.ica\n",
            "AllData/HCP_hp2000/66.ica\n",
            "AllData/HCP_hp2000/67.ica\n",
            "AllData/HCP_hp2000/68.ica\n",
            "AllData/HCP_hp2000/69.ica\n",
            "AllData/HCP_hp2000/7.ica\n",
            "AllData/HCP_hp2000/70.ica\n",
            "AllData/HCP_hp2000/71.ica\n",
            "AllData/HCP_hp2000/72.ica\n",
            "AllData/HCP_hp2000/73.ica\n",
            "AllData/HCP_hp2000/74.ica\n",
            "AllData/HCP_hp2000/75.ica\n",
            "AllData/HCP_hp2000/76.ica\n",
            "AllData/HCP_hp2000/77.ica\n",
            "AllData/HCP_hp2000/78.ica\n",
            "AllData/HCP_hp2000/79.ica\n",
            "AllData/HCP_hp2000/8.ica\n",
            "AllData/HCP_hp2000/80.ica\n",
            "AllData/HCP_hp2000/81.ica\n",
            "AllData/HCP_hp2000/82.ica\n",
            "AllData/HCP_hp2000/83.ica\n",
            "AllData/HCP_hp2000/84.ica\n",
            "AllData/HCP_hp2000/85.ica\n",
            "AllData/HCP_hp2000/86.ica\n",
            "AllData/HCP_hp2000/87.ica\n",
            "AllData/HCP_hp2000/88.ica\n",
            "AllData/HCP_hp2000/89.ica\n",
            "AllData/HCP_hp2000/9.ica\n",
            "AllData/HCP_hp2000/90.ica\n",
            "AllData/HCP_hp2000/91.ica\n",
            "AllData/HCP_hp2000/92.ica\n",
            "AllData/HCP_hp2000/93.ica\n",
            "AllData/HCP_hp2000/94.ica\n",
            "AllData/HCP_hp2000/95.ica\n",
            "AllData/HCP_hp2000/96.ica\n",
            "AllData/HCP_hp2000/97.ica\n",
            "AllData/HCP_hp2000/98.ica\n",
            "AllData/HCP_hp2000/99.ica\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}